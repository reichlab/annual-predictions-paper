\documentclass{article}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amssymb,amsmath}
\usepackage{microtype}
\usepackage{cite}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{enumerate}
\usepackage[english]{babel}
\usepackage{wrapfig}
\usepackage{multicol}
\usepackage{textcomp}
\usepackage{float}
\usepackage{array}
\usepackage{xr-hyper}
\usepackage{hyperref}
\title{Supplemental Material}
\author{Stephen A. Lauer*, Krzysztof Sakrejda, Evan L. Ray, Lindsay T. Keegan, Qifang Bi, \\ Paphanij Suangtho, Soawapak Hinjoy, Sopon Iamsirithaworn, Suthanun Suthachana, \\ Yongjua Laosiritaworn, Derek A.T. Cummings, Justin Lessler, and Nicholas G. Reich}

\begin{document}

\maketitle

<<libraries, include=FALSE>>=
library(dplyr)
library(ggplot2)
library(maptools)
library(xtable)
library(mgcv)
library(mapproj)
library(scales)
library(grid)
library(tidyr)
library(ggrepel)
library(MapColoring)

opts_knit$set(root.dir = here::here())
@

<<setup, include=FALSE>>=
thai_prov_data <- read.csv("data/thai-prov-data.csv")

FIRST_YEAR <- 2000
LAST_TEST_YEAR <- 2014
LAST_YEAR <- 2014
FIRST_TEST_YEAR <- 2010
MAX_KNOTS <- 8
INCIDENCE <- TRUE
OVERWRITE <- FALSE

cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

source("R/annual-forecasting-utilities.R")
##### All of data required to make these visuals
#####

## read in latest data for prediction
most_recent_dat <- find_recent_file(name_start = "annual-pred-data",
                                    path="data/")

dengue_dat <- read.csv(most_recent_dat)[,-1]

## data used for cross validation
cv_dat <- filter(dengue_dat, year<FIRST_TEST_YEAR)

## map data
world <- readShapeSpatial("data/map-data/ne_10m_admin_1_states_provinces.shp")
thai_map <- world[world$adm0_a3=="THA",]
thai_map <- thai_map[!is.na(thai_map$woe_name),]
thai_map@data <- thai_map@data %>%
    left_join(select(thai_prov_data, FIPS, MOPH_Admin_Code),
              by = c("gns_adm1" = "FIPS"))

## if we have run simulations in the past, find and load them
most_recent_cv <- find_recent_file(name_start = "cv-train",
                                   path="data/")
cv_train <- readRDS(most_recent_cv)

### create a table of all the best single covariate full country models

## label each variable if they are available to group 1, 2, or 3
var_set <- data_frame(var = names(dengue_dat),
                      set = c(rep(1, 17), rep(2, 10), rep(3, 11)))

table_dat <- find_recent_file("covariate-table", "data/") %>%
    read.csv()

## find best models given CV data
cv_mae <- cv_train %>%
    filter(num_cov>1|
               num_cov==1 &
               knots == table_dat$best_k[match(model_covs, table_dat$model_covs)]) %>%
    group_by(year, formula, model_covs, num_cov) %>%
    summarise(year_mae = mean(abs(log(obs_counts)-log(pred_counts)))) %>%
    group_by(formula, model_covs, num_cov) %>%
    summarise(mae = mean(year_mae),
              cv_sd = sd(year_mae)) %>%
    group_by(num_cov) %>%
    filter(mae == min(mae)) %>%
    ungroup() %>%
    arrange(mae, num_cov)

cv_mae$aic <- NA
for(i in 1:nrow(cv_mae))
    cv_mae$aic[i] <- gam(formula(cv_mae$formula[i]), data=cv_dat, family=nb()) %>% AIC()

best_cv_formula <- as.character(cv_mae$formula[1])

best_models <- cv_mae %>%
    select(formula, model_covs, num_cov, cv_mae=mae) %>%
    slice(1)

reduced_model <- cv_mae %>%
    ungroup() %>%
    filter(num_cov<=num_cov[which.min(mae)],
           mae<=min(mae)+cv_sd[which.min(mae)]) %>%
    arrange(num_cov) %>%
    slice(1) %>%
    select(-cv_sd, cv_mae=mae)

cv_median_mae <- cv_dat %>%
    group_by(pid) %>%
    mutate(median_rate = median(obs)) %>%
    ungroup() %>%
    summarise(formula = "",
              model_covs = "",
              num_cov = 0,
              cv_mae = mean(abs(log(obs) - log(median_rate))))

best_cv_formula <- as.character(cv_median_mae$formula[1])

best_models <- bind_rows(best_models, reduced_model, cv_median_mae)
best_models$model <- c("WIP",
                       "Incidence-only",
                       "Baseline")

## testing phase predictions
most_recent_test <- find_recent_file(name_start = "test-preds",
                                     path="data/")
test_preds <- readRDS(most_recent_test)

test_preds <- test_preds %>%
    filter(num_cov %in% c(min(num_cov), max(num_cov)))

## baseline predictor using median provincial rates over past 10 seasons
past_season_prob <- function(pred_year,
                             years_back,
                             pred_pid,
                             counts,
                             incidence) {
    annual_rates <- counts %>%
        ungroup() %>%
        filter(year >= pred_year - years_back,
               year < pred_year,
               pid == pred_pid)
    if(incidence)
        baseline <- median(100000*annual_rates$obs/
                               annual_rates$population) else
                                   baseline <- median(annual_rates$obs)
                               return(baseline)
}

test_dat <- dengue_dat %>%
    filter(year >= FIRST_TEST_YEAR,
           year <= LAST_TEST_YEAR)
test_dat$baseline <- NA
for(i in 1:nrow(test_dat)){
    test_dat$baseline[i] <-
        past_season_prob(pred_year=test_dat$year[i],
                         years_back=FIRST_TEST_YEAR-FIRST_YEAR,
                         pred_pid=test_dat$pid[i],
                         counts=dengue_dat,
                         incidence=INCIDENCE)
}

final_preds_sum <- test_preds %>%
    left_join(test_dat %>% select(year, pid, population, baseline)) %>%
    mutate(obs_rate=100000*obs_counts/population,
           pred_rate=100000*pred_counts/population) %>%
    group_by(year, pid, group, num_cov, population, obs_rate, baseline) %>%
    summarise(pred_rate_median = median(pred_rate),
              bin_pct = mean(floor(obs_rate)==floor(pred_rate))+10^-5) %>%
    mutate(ae_pred = abs(log(obs_rate) - log(pred_rate_median)),
           ae_pred_pct = ae_pred / obs_rate,
           ae_baseline = abs(log(obs_rate) - log(baseline)),
           ae_baseline_pct = ae_baseline / obs_rate,
           rel_ae = ae_pred / ae_baseline,
           win = ae_pred < ae_baseline,
           log_score=log(bin_pct)) %>%
    ungroup()

overall_mae <- final_preds_sum %>%
    group_by(num_cov) %>%
    summarise(N = n(),
              mean_obs_rate = mean(obs_rate, na.rm = TRUE),
              mae_pred = mean(ae_pred, na.rm = TRUE),
              mae_baseline = mean(ae_baseline),
              rel_mae = mae_pred / mae_baseline,
              win_pct = mean(win, na.rm = TRUE),
              avg_bin_pct = mean(bin_pct),
              avg_log_score = mean(log_score))

pid_mae <- final_preds_sum %>%
    group_by(pid, num_cov) %>%
    summarise(N = n(),
              mean_obs_rate = mean(obs_rate, na.rm = TRUE),
              var_obs_rate = var(obs_rate, na.rm = TRUE),
              mae_pred = mean(ae_pred, na.rm = TRUE),
              mae_baseline = mean(ae_baseline),
              rel_mae = mae_pred / mae_baseline,
              win_pct = mean(win, na.rm = TRUE),
              avg_bin_pct = mean(bin_pct),
              avg_log_score = mean(log_score)) %>%
    ungroup()

annual_mae <- final_preds_sum %>%
    group_by(year, num_cov) %>%
    summarise(N = n(),
              mean_obs_rate = mean(obs_rate, na.rm = TRUE),
              mae_pred = mean(ae_pred, na.rm = TRUE),
              mae_baseline = mean(ae_baseline),
              rel_mae = mae_pred / mae_baseline,
              win_pct = mean(win, na.rm = TRUE),
              avg_bin_pct = mean(bin_pct),
              avg_log_score = mean(log_score)) %>%
    ungroup()

province_data <- final_preds_sum %>%
    left_join(thai_prov_data, by = c("pid" = "FIPS"))

moph_mae <- province_data %>%
    group_by(MOPH_Admin_Code, num_cov) %>%
    summarise(N = n(),
              mean_obs_rate = mean(obs_rate, na.rm = TRUE),
              mae_pred = mean(ae_pred, na.rm = TRUE),
              mae_baseline = mean(ae_baseline),
              rel_mae = mae_pred/mae_baseline,
              win_pct = mean(win, na.rm = TRUE),
              avg_bin_pct = mean(bin_pct),
              avg_log_score = mean(log_score)) %>%
    ungroup()

final_table <- test_preds %>%
    group_by(pid, year, num_cov, obs_counts) %>%
    summarise(pred_count_median = median(pred_counts)) %>%
    group_by(num_cov) %>%
    summarise(test_mae = mean(abs(log(obs_counts) - log(pred_count_median))))

final_model_covs <- final_table$num_cov[which.min(final_table$test_mae)]

best_preds <- test_preds %>%
    filter(num_cov==final_model_covs)

best_preds_sum <- final_preds_sum %>%
    filter(num_cov == final_model_covs)
@

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}
\includegraphics[width=\maxwidth]{figure/annual-cases-graph-1} \caption{Aggregated time series of dengue hemorrhagic fever cases from 2000-2014.}\label{fig:annual-cases-graph}
\end{figure}


\end{knitrout}

<<moph-region-map, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Map of the Thailand Ministry of Public Health administrative regions (MOPH regions). These 13 MOPH regions are geographically clustered sets of 4-8 provinces (with the exception of Bangkok which is its own region) co-operatively managed by a regional health office.", fig.lp="sup:", fig.pos='H'>>=
## create a map of MOPH regions with own polygons, so we can find centroids of each region
## code to make this was found on: https://gis.stackexchange.com/questions/63577/joining-polygons-in-r
## join the polygons by MOPH region
moph_poly <- unionSpatialPolygons(thai_map, thai_map@data$MOPH_Admin_Code)
## condense dataframe from nrow=76 to nrow=13
moph_df <- as.data.frame(thai_map) %>%
    group_by(MOPH_Admin_Code) %>%
    summarise(area_sqkm=sum(area_sqkm)) %>%
    ungroup
## row names need to line up with MOPH Admin Code
row.names(moph_df) <- as.character(moph_df$MOPH_Admin_Code)
## make SpatialPolygonsDataFrame
moph_map <- SpatialPolygonsDataFrame(moph_poly, moph_df)
## find centroids. code found on: https://gis.stackexchange.com/questions/43543/how-to-calculate-polygon-centroids-in-r-for-non-contiguous-shapes
moph_centroids <- getSpPPolygonsLabptSlots(moph_map)
colnames(moph_centroids) <- c("longitude", "latitude")
moph_map@data <- cbind(moph_map@data, moph_centroids)
## Bangkok label covers Bangkok, so need to move it and have arrow
moph_map@data$BKK_Code <- ifelse(moph_map@data$MOPH_Admin_Code==0,
                                  0, NA)
## Other MOPH Regions should stay in place
moph_map@data$MOPH_Code <- ifelse(moph_map@data$MOPH_Admin_Code==0,
                                         NA, moph_map@data$MOPH_Admin_Code)
thai_locs <- fortify(moph_map)

color_order <- getColoring(moph_map)[c(1,2,6:13,3:5)]+1
color_order[9] <- 5

ggplot(moph_map@data, aes(map_id=MOPH_Admin_Code)) +
    geom_map(aes(fill=as.factor(MOPH_Admin_Code)),
             color = "black",
             map=thai_locs) +
    expand_limits(x = thai_locs$long, y = thai_locs$lat) +
    geom_label(aes(label=MOPH_Code, x=longitude, y=latitude)) +
    geom_label_repel(aes(label=BKK_Code, x=longitude, y=latitude), nudge_y=-1, arrow=arrow(angle=0)) +
    scale_fill_manual("MOPH\nRegion", values=cbPalette[color_order]) +
    theme(axis.ticks = element_blank(),
          axis.text = element_blank(),
          panel.background = element_rect(fill = "transparent", colour = NA),
          plot.title = element_text(hjust=-.05, face="bold"),
          legend.position="none") +
    coord_map(projection="mercator") + ## to keep scaling right
    xlab("") + ylab("")
@

\begin{table}[H]
    \centering
    \begin{tabular}{ l l c c }
        \hline
        Covariate Type & Covariate Name & Incidence-only & WIP \\
        \hline \hline
        \multirow{4}{*}{Incidence} & estimated relative susceptibility rate & &   \\
        & last high-season incidence rate & & \\
        & last post-season incidence rate & & \\
        & pre-season incidence rate & \checkmark & \checkmark  \\ \hline
        \multirow{2}{*}{Demographics} & population per square kilometer & & \\
        & provincial population & & \checkmark \\ \hline
        \multirow{5}{*}{Humidity} & maximum low-season humidity & & \\
        & minimum low-season humidity & & \\
        & mean January humidity & & \\
        & mean February humidity & & \\
        & mean March humidity & & \\ \hline
        \multirow{12}{*}{Rainfall} & maximum low-season rainfall (NOAA) & & \\
        & total low-season rainfall (ESRL) & & \\
        & total low-season rainfall (NOAA) & & \\
        & maximum January rainfall (NOAA) & & \\
        & total January rainfall (ESRL) & & \checkmark \\
        & total January rainfall (NOAA) & & \\
        & maximum February rainfall (NOAA) & & \\
        & total February rainfall (ESRL) & & \\
        & total February rainfall (NOAA) & & \\
        & maximum March rainfall (NOAA) & & \\
        & total March rainfall (ESRL) & & \\
        & total March rainfall (NOAA) & & \\ \hline
        \multirow{12}{*}{Temperature} & maximum low-season temperature (NCDC) & & \\
        & mean low-season temperature (ESRL) & & \checkmark \\
        & minimum low-season temperature (NCDC) & & \\
        & mean January temperature (ESRL) & & \checkmark \\
        & mean January temperature (NCDC) & & \\
        & mean January temperature (NOAA) & & \\
        & mean February temperature (ESRL) & & \\
        & mean February temperature (NCDC) & & \\
        & mean February temperature (NOAA) & & \\
        & mean March temperature (ESRL) & & \\
        & mean March temperature (NCDC) & & \\
        & mean March temperature (NOAA) & & \\
        \hline
        \end{tabular}
    \caption{List of all covariates considered for inclusion and models for which they were selected}
    \label{sup:covs}
\end{table}

<<overall-table, echo=FALSE, results='asis', warning=FALSE, fig.pos="center", message=FALSE>>=
outbreak_dat <- dengue_dat %>%
    transmute(pid,
              sim=year,
              sim_rate=100000*obs/population) %>%
    full_join(select(dengue_dat, pid, year, obs, population)) %>%
    filter(year>=2010,
           year<2015,
           sim<year,
           sim>=year-10) %>%
    group_by(pid, year) %>%
    mutate(pid_median = median(sim_rate),
           pid_sd = sd(sim_rate),
           outbreak_threshold = pid_median+2*pid_sd,
           baseline_pred=mean(sim_rate>outbreak_threshold)) %>%
    select(pid, year, outbreak_threshold) %>%
    distinct(.keep_all=TRUE)

reference_dat <- test_dat %>%
    left_join(outbreak_dat) %>%
    transmute(year=year,
              pid=pid,
              group=NA,
              num_cov=0,
              population=population,
              obs_rate=100000*obs/population,
              baseline=baseline,
              pred_rate=baseline,
              ae_pred=abs(log(obs_rate)-log(pred_rate)),
              ae_pred_pct = ae_pred / obs_rate,
              ae_baseline = abs(log(obs_rate) - log(baseline)),
              ae_baseline_pct = ae_baseline / obs_rate,
              rel_ae = ae_pred / ae_baseline,
              win = NA,
              outbreak_observed = as.numeric(obs_rate>outbreak_threshold))

pi_dat <- test_preds %>%
    left_join(test_dat %>% select(pid, year, population)) %>%
    mutate(obs_rate=100000*obs_counts/population,
           pred_rate=100000*pred_counts/population) %>%
    group_by(pid, year, num_cov, population, obs_rate) %>%
    summarise(
        pred_10=quantile(pred_rate, probs=.1),
        pred_90=quantile(pred_rate, probs=.9),
        pred_rate_median=median(pred_rate),
        pi_coverage_80=mean(obs_rate>=pred_10 & obs_rate<=pred_90)) %>%
    mutate(abs_error=abs(log(pred_rate_median)-log(obs_rate))) %>%
    ungroup() %>%
    left_join(select(thai_prov_data, -Population), by=c("pid"="FIPS"))

overall_table <- reference_dat %>%
    group_by(num_cov) %>%
    summarise(N = n(),
              mean_obs_rate = mean(obs_rate, na.rm = TRUE),
              mae_pred = mean(ae_pred, na.rm = TRUE),
              mae_baseline = mean(ae_baseline),
              rel_mae = mae_pred / mae_baseline,
              win_pct = mean(win, na.rm = TRUE),
              avg_bin_pct = NA,
              avg_log_score = NA,
              aic=NA) %>%
    bind_rows(overall_mae) %>%
    left_join(
        pi_dat %>%
            group_by(num_cov) %>%
            summarise(pi_coverage = mean(pi_coverage_80))
    ) %>%
    arrange(desc(num_cov)) %>%
    transmute(Model = ifelse(num_cov==max(final_table$num_cov),
                             "\\hline WIP",
                             ifelse(num_cov==0,
                                    "Baseline",
                                    "Incidence-only")),
              MAE = ifelse(mae_pred==min(mae_pred, na.rm=T),
                           paste0("\\textbf{",
                                  formatC(mae_pred,digits=2, format="f"),
                                  "}"),
                           formatC(mae_pred,digits=2, format="f")),
              `rMAE` = ifelse(rel_mae==min(rel_mae, na.rm=T),
                                      paste0("\\textbf{",
                                             formatC(rel_mae,
                                                     digits=2,
                                                     format="f"),
                                             "}"),
                                      formatC(rel_mae,digits=2, format="f")),
              `\\% of forecasts better than baseline` = ifelse(win_pct!=min(win_pct, na.rm=T),
                                            paste0("\\textbf{",
                                                   formatC(100*win_pct,
                                                           digits=1,
                                                           format="f"),
                                                   "}"),
                                            formatC(100*win_pct,
                                                    digits=1,
                                                    format="f")),
              `80\\% PI coverage` = ifelse(abs(.80-pi_coverage)!=
                                               max(abs(.80-pi_coverage),
                                                   na.rm=T),
                                            paste0("\\textbf{",
                                                   formatC(100*pi_coverage,
                                                           digits=1,
                                                           format="f"),
                                                   "}"),
                                            formatC(100*pi_coverage,
                                                    digits=1,
                                                    format="f")),
              AIC = ifelse(aic==min(aic, na.rm=T),
                                            paste0("\\textbf{",
                                                   formatC(aic,
                                                           digits=0,
                                                           format="f"),
                                                   "}"),
                                            formatC(aic,
                                                    digits=0,
                                                    format="f")))

print(xtable(overall_table,
             caption="Results for each model across all regions and years in the testing phase. Numbers in bold highlight which model performed best for each metric.",
             label = "sup:overall",
             digits = c(0,0,2,2,1,1,0),
             align = c("l","l","r", "b{1cm}", "b{1.35cm}","b{1.5cm}", "b{1cm}")),
      include.rownames = FALSE,
      table.placement="H",
      sanitize.text.function=identity)
@

<<annual-table, echo=FALSE, results='asis', warning=FALSE, fig.pos="center", message=FALSE>>=
## annual MAEs
annual_table <- reference_dat %>%
    left_join(thai_prov_data, by = c("pid" = "FIPS")) %>%
    group_by(year, num_cov) %>%
    summarise(N = n(),
              mean_obs_rate = mean(obs_rate, na.rm = TRUE),
              num_outbreaks = sum(outbreak_observed, na.rm=TRUE),
              mae_pred = mean(ae_pred, na.rm = TRUE),
              mae_baseline = mean(ae_baseline),
              rel_mae = mae_pred / mae_baseline,
              win_pct = mean(win, na.rm = TRUE),
              avg_bin_pct = NA,
              avg_log_score = NA) %>%
    bind_rows(annual_mae) %>%
    left_join(
        pi_dat %>%
            group_by(num_cov, year) %>%
            summarise(pi_coverage = mean(pi_coverage_80))
    ) %>%
    arrange(year, desc(num_cov)) %>%
    group_by(year) %>%
    transmute(Model = ifelse(num_cov==max(final_table$num_cov),
                             "\\hline WIP",
                             ifelse(num_cov==0,
                                    "Baseline",
                                    "Incidence-only")),
              Year = ifelse(Model=="Incidence-only",
                            as.character(year),
                            ""),
              `Mean provincial incidence` = ifelse(Model=="Incidence-only",
                                                   round(mean_obs_rate),
                                                   ""),
              Outbreaks = ifelse(Model=="Incidence-only",
                                           max(num_outbreaks, na.rm=T),
                                           ""),
              MAE = ifelse(mae_pred==min(mae_pred, na.rm=T),
                           paste0("\\textbf{",
                                  formatC(mae_pred,digits=2, format="f"),
                                  "}"),
                           formatC(mae_pred,digits=2, format="f")),
              `rMAE` = ifelse(rel_mae==min(rel_mae, na.rm=T),
                                      paste0("\\textbf{",
                                             formatC(rel_mae,
                                                     digits=2,
                                                     format="f"),
                                             "}"),
                                      formatC(rel_mae,digits=2, format="f")),
              `\\% of forecasts better than baseline` = ifelse(win_pct!=min(win_pct, na.rm=T),
                                            paste0("\\textbf{",
                                                   formatC(100*win_pct,
                                                           digits=1,
                                                           format="f"),
                                                   "}"),
                                            formatC(100*win_pct,digits=1, format="f")),
              `80\\% PI coverage` = ifelse(abs(.80-pi_coverage)!=
                                               max(abs(.80-pi_coverage),
                                                   na.rm=T),
                                            paste0("\\textbf{",
                                                   formatC(100*pi_coverage,
                                                           digits=1,
                                                           format="f"),
                                                   "}"),
                                            formatC(100*pi_coverage,
                                                    digits=1,
                                                    format="f"))) %>%
    ungroup() %>%
    select(-year)

print(xtable(annual_table,
             caption="Annual results for each model across all regions in the testing phase. Numbers in bold highlight which model performed best for each metric in each year.",
             label = "sup:annual",
             digits = c(0,0,0,0,0,2,2,1,1),
             align = "llcb{1.55cm}b{1.2cm}rb{1cm}b{1.35cm}b{1.3cm}"),
      include.rownames = FALSE,
      table.placement="H",
      sanitize.text.function=identity)
@

As displayed in Table S\ref{sup:moph}, the smallest mean absolute error (MAE) by any model for any region was for Bangkok (MOPH region 0) using the incidence-only model (MAE=0.286).
However, because the baseline MAE for Bangkok was only slightly higher (MAE=0.289), the incidence-only model relative MAE (rMAE) was the second-largest of any region (rMAE=0.99).
Thus, even though the incidence-only model accurately forecasted DHF incidence in Bangkok, it didn't add much value over a ten-year median, due in part to there being no outbreaks in Bangkok during the testing phase.

Conversely, the incidence-only model had about twice as much error in MOPH region 12 (MAE=0.59) as in Bangkok.
However, the baseline model had nearly three times as much error than in Bangkok (MAE=0.86), so the incidence-only rMAE for MOPH region 12 was the lowest of any model for any region (rMAE=0.69).
Thus, despite greater absolute error from the incidence-only model forecasts, there was more added benefit for that region over the baseline forecasts than for Bangkok.
These examples demonstrate how MAE and rMAE can be used in tandem to give a more complete evaluation of model performance.

<<moph-table, echo=FALSE, results='asis', warning=FALSE, fig.pos="center", message=FALSE>>=
## MOPH MAEs
moph_table <- reference_dat %>%
    left_join(thai_prov_data, by = c("pid" = "FIPS")) %>%
    group_by(MOPH_Admin_Code, num_cov) %>%
    summarise(N = n(),
              mean_obs_rate = mean(obs_rate, na.rm = TRUE),
              num_outbreaks = sum(outbreak_observed, na.rm=TRUE),
              mae_pred = mean(ae_pred, na.rm = TRUE),
              mae_baseline = mean(ae_baseline),
              rel_mae = mae_pred / mae_baseline,
              win_pct = mean(win, na.rm = TRUE)) %>%
    bind_rows(moph_mae) %>%
    left_join(
        pi_dat %>%
            group_by(num_cov, MOPH_Admin_Code) %>%
            summarise(pi_coverage = mean(pi_coverage_80))
    ) %>%
    group_by(MOPH_Admin_Code) %>%
    mutate(order_factor=min(rel_mae)) %>%
    ungroup() %>%
    arrange(order_factor, desc(num_cov)) %>%
    group_by(MOPH_Admin_Code) %>%
    transmute(Model = ifelse(num_cov==max(final_table$num_cov),
                             "\\hline WIP",
                             ifelse(num_cov==0,
                                    "Baseline",
                                    "Incidence-only")),
              `MOPH Region` = ifelse(Model=="Incidence-only",
                              as.character(MOPH_Admin_Code),
                              ""),
              Provinces = ifelse(Model=="Incidence-only",
                                             N/5,
                                             ""),
              `Mean provincial incidence` = ifelse(Model=="Incidence-only",
                                                   round(mean_obs_rate),
                                                   ""),
              Outbreaks = ifelse(Model=="Incidence-only",
                                           max(num_outbreaks, na.rm=T),
                                           ""),
              MAE = ifelse(mae_pred==min(mae_pred, na.rm=T),
                           paste0("\\textbf{",
                                  formatC(mae_pred,digits=2, format="f"),
                                  "}"),
                           formatC(mae_pred,digits=2, format="f")),
              `rMAE` = ifelse(rel_mae==min(rel_mae, na.rm=T),
                                      paste0("\\textbf{",
                                             formatC(rel_mae, digits=2, format="f"),
                                             "}"),
                                      formatC(rel_mae,digits=2, format="f")),
              `\\% of forecasts better than baseline` = ifelse(win_pct!=min(win_pct, na.rm=T),
                                            paste0("\\textbf{",
                                                   formatC(100*win_pct,digits=1, format="f"),
                                                   "}"),
                                            formatC(100*win_pct,digits=1, format="f")),
              `80\\% PI coverage` = ifelse(abs(.80-pi_coverage)!=max(abs(.80-pi_coverage), na.rm=T),
                                            paste0("\\textbf{",
                                                   formatC(100*pi_coverage,digits=1, format="f"),
                                                   "}"),
                                            formatC(100*pi_coverage,digits=1, format="f"))) %>%
    ungroup() %>%
    select(-MOPH_Admin_Code)

print(xtable(moph_table,
             caption="Regional results for each model across all years in the testing phase. Numbers in bold highlight which model performed best for each metric in each region. The regions are sorted by best model performance using relative mean absolute error (rMAE) from lowest to highest.",
             label = "sup:moph",
             digits = c(0,0,0,0,0,0,2,2,1,1),
             align = "llb{1.1cm}b{1.1cm}b{1.55cm}b{1.2cm}rb{1cm}b{1.35cm}b{1.3cm}"),
      include.rownames = FALSE,
      table.placement="H",
      sanitize.text.function=identity)
@

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}[H]
\includegraphics[width=\maxwidth]{figure/pred-interval-plot-wip-1} \caption{Weather, incidence, and population (WIP) model forecasts for each year of the testing phase compared to the baseline forecasts and the observed values. Forecasts for the annual dengue hemorrhagic fever (DHF) incidence rate, per 100,000 population, from the WIP model (blue triangles with gray 80\% prediction intervals), baseline forecasts (red circles), and observed values (black x's) for each province and year in the testing phase.}\label{fig:pred-interval-plot-wip}
\end{figure}
\end{knitrout}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}[H]
\includegraphics[width=\maxwidth]{figure/rel-mae-province-1} \caption{Geographic variation in model and performance by province. \textbf{(a)} The best fitted model in the testing phase for each Thai province, which shows spatial patterns of performance. \textbf{(b)} The relative mean absolute error of the forecasts for each province from the models in (a) over the baseline forecasts. Provinces with: less error than the baseline are blue, more error than the baseline are red, and equal to the baseline are white.}\label{fig:rel-mae-province}
\end{figure}
\end{knitrout}

The receiver operating characteristic (ROC) curves for the incidence-only and WIP model outbreak forecasts for the testing phase are both significantly above the line of no-discrimination, but are not significantly different from each other (Figure S\ref{fig:roc-wip}). The incidence-only model area under the ROC curve (AUC; Estimate: 84.2\%, 95\%CI: 78.5-89.9\%) was slightly larger than that of the WIP model AUC (82.9\%, 76.3-89.6\%). The sensitivity of the WIP model is marginally larger than that of the incidence-only model when specificity is large, suggesting that the WIP model showed very slightly better performance than the incidence-only model at larger outbreak thresholds.

Alternatively, the predictive distributions samples used to make the outbreak forecasts could have been obtained by estimating parameters in a Bayesian framework, including drawing posterior samples of the dispersion parameter.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}[H]
\includegraphics[width=\maxwidth]{figure/roc-wip-1} \caption{Comparison of receiver operating characteristic (ROC) curves by model. The ROC curve based on the incidence-only model and weather, incidence, and population (WIP) models' sensitivity and specificity on outbreak forecasts during the testing phase. Both curves are comfortably above the line of no-discrimination (dashed), indicating that their outbreak forecasts are better than random. The AUC for the WIP model (82.9\%) is a bit lower than that of the incidence-only model (84.2\%).}\label{fig:roc-wip}
\end{figure}
\end{knitrout}

<<supplemental sheets, include=FALSE>>=
##### make annual sheets like those for distribution to Thai MOPH
#####
best_moph_mae <- moph_mae %>%
    group_by(MOPH_Admin_Code) %>%
    filter(rel_mae==min(rel_mae))

best_test_covs <- best_preds$model_covs[1]

for(delivery_year in FIRST_TEST_YEAR:LAST_YEAR){
    ## if the file already exists, skip to next year
    if(!find_recent_file(
        name_start=paste0("ST",
                          (delivery_year-FIRST_TEST_YEAR+5),
                          "-annual-prediction-deliverable-",
                          delivery_year),
        path="manuscript/") %>% is.na() &
       !OVERWRITE)
        next

    province_sd_dat <- dengue_dat %>%
        transmute(pid,
                  sim=year,
                  sim_rate=100000*obs/population) %>%
        full_join(select(dengue_dat, pid, year, population)) %>%
        filter(year==delivery_year,
               sim<year,
               sim>=year-10) %>%
        group_by(pid, year, population) %>%
        summarise(pid_median=median(sim_rate),
                  pid_sd = sd(sim_rate),
                  pid_1sd = pid_median+pid_sd,
                  pid_2sd = pid_median+2*pid_sd)

    new_pi_dat <- best_preds %>%
            filter(year==delivery_year) %>%
            left_join(province_sd_dat) %>%
            mutate(obs_rate=100000*obs_counts/population,
                   pred_rate=100000*pred_counts/population) %>%
            group_by(pid, year, obs_rate, pid_median) %>%
            summarise(pred_10=quantile(pred_counts, probs=.1),
                      pred_90=quantile(pred_counts, probs=.9),
                      pred_count_median=quantile(pred_counts, probs=.5),
                      prob_gt_1sd=mean(pred_rate>pid_1sd),
                      prob_gt_2sd=mean(pred_rate>pid_2sd)) %>%
            ungroup()

    annual_deliverable <- dengue_dat %>%
        left_join(select(thai_prov_data, -Population),
                  by=c("pid"="FIPS")) %>%
        left_join(new_pi_dat) %>%
        filter(year>=delivery_year-1,
               year<=delivery_year) %>%
        group_by(pid) %>%
        mutate(last_year_obs=obs[which.min(year)]) %>%
        filter(year==delivery_year) %>%
        ungroup() %>%
        transmute(pid,
                  Province,
                  `MOPH Admin Code`=MOPH_Admin_Code,
                  `Last Year Cases`=ceiling(last_year_obs),
                  `10-year Median`=ceiling(population*pid_median/100000),
                  `Predicted Cases`=ceiling(pred_count_median),
                  `Predicted:Median Ratio`=round(pred_count_median/(population*pid_median/100000),2),
                  `Lower Bound`=ceiling(pred_10),
                  `Upper Bound`=ceiling(pred_90),
                  `Predicted Incidence Rate`=round(100000*pred_count_median/population),
                  `Probability Above 1SD`=round(prob_gt_1sd,2),
                  `Probability Above 2SD`=round(prob_gt_2sd,2)) %>%
        arrange(pid)

    if(delivery_year==FIRST_TEST_YEAR){
        annual_deliverable$`Last Year Cases` <-
            ceiling(dengue_dat$obs[dengue_dat$year==(FIRST_TEST_YEAR-1)])
    }

    write.csv(annual_deliverable,
              paste0("manuscript/ST",
                     (delivery_year-FIRST_TEST_YEAR+5),
                     "-annual-prediction-deliverable-",
                     delivery_year,"-",Sys.Date(),
                     ".csv"))
}
@

\end{document}
